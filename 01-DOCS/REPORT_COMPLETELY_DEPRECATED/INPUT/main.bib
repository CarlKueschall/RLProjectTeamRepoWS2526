% Core RL Algorithms
@inproceedings{fujimoto2018,
  author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  title = {Addressing Function Approximation Error in Actor-Critic Methods},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  series = {PMLR},
  volume = {80},
  pages = {1587--1596},
  year = {2018}
}

@article{haarnoja2018,
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  journal = {arXiv preprint arXiv:1812.05905},
  year = {2018}
}

@article{lillicrap2015,
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  title = {Continuous Control with Deep Reinforcement Learning},
  journal = {arXiv preprint arXiv:1509.02971},
  year = {2015}
}

% Self-Play and PFSP
@article{vinyals2019,
  author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"e}l and Jaderberg, Max and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and others},
  title = {Grandmaster Level in {StarCraft II} Using Multi-Agent Reinforcement Learning},
  journal = {Nature},
  volume = {575},
  number = {7782},
  pages = {350--354},
  year = {2019}
}

@article{selfplay2024,
  author = {Anonymous},
  title = {A Survey on Self-play Methods in Reinforcement Learning},
  journal = {arXiv preprint arXiv:2408.01072},
  year = {2024}
}

@article{jaderberg2017,
  author = {Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M. and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and others},
  title = {Population Based Training of Neural Networks},
  journal = {arXiv preprint arXiv:1711.09846},
  year = {2017}
}

% Reward Shaping
@inproceedings{ng1999,
  author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart J.},
  title = {Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
  booktitle = {Proceedings of the 16th International Conference on Machine Learning},
  pages = {278--287},
  year = {1999}
}

% Environments and APIs
@article{towers2024,
  author = {Towers, Mark and Terry, Jordan K. and Kwiatkowski, Ariel and Balis, John U. and Cola, Gianluca de and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and KG, Arjun and Krimmel, Markus and others},
  title = {Gymnasium: A Standard Interface for Reinforcement Learning Environments},
  journal = {arXiv preprint arXiv:2407.17032},
  year = {2024}
}

@article{brockman2016,
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  title = {OpenAI Gym},
  journal = {arXiv preprint arXiv:1606.01540},
  year = {2016}
}

@misc{martius2024,
  author = {Martius, Georg},
  title = {hockey-env: A Simple Laser-Hockey Gym Environment for RL Agents},
  howpublished = {GitHub repository},
  url = {https://github.com/martius-lab/hockey-env},
  year = {2024}
}

@misc{comprl2024,
  author = {Martius, Georg},
  title = {CompRL -- RL Competition Server: A Competition Server for Running 2-Player Game Competitions},
  howpublished = {GitHub repository},
  url = {https://github.com/martius-lab/comprl},
  year = {2024}
}

@techreport{herbrich2006,
  author = {Herbrich, Ralf and Minka, Tom and Graepel, Thore},
  title = {{TrueSkill}: A Bayesian Skill Rating System},
  institution = {Microsoft Research},
  number = {MSR-TR-2006-80},
  year = {2006}
}

% Software Stack
@misc{perplexity2024,
  author = {Perplexity AI},
  title = {Perplexity AI: AI-Powered Search Engine},
  year = {2024},
  url = {https://www.perplexity.ai/},
  note = {Accessed 2024-2025}
}

@inproceedings{paszke2019,
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {32},
  year = {2019}
}

@misc{biewald2020,
  author = {Biewald, Lukas},
  title = {Experiment Tracking with Weights and Biases},
  year = {2020},
  note = {Software available from wandb.com},
  url = {https://www.wandb.com/}
}

% Future Work - Model-Based RL
@article{hafner2023,
  author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  title = {Mastering Diverse Domains through World Models},
  journal = {Nature},
  year = {2024},
  note = {arXiv:2301.04104}
}

@article{hansen2023,
  author = {Hansen, Nicklas and Su, Hao and Wang, Xiaolong},
  title = {{TD-MPC2}: Scalable, Robust World Models for Continuous Control},
  journal = {arXiv preprint arXiv:2310.16828},
  year = {2023}
}

% Related Work (from project spec)
@inproceedings{hessel2018,
  author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Boris and Azar, Mohammad Gheshlaghi and Silver, David},
  title = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {32},
  number = {1},
  year = {2018}
}

@inproceedings{wang2016,
  author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and Freitas, Nando de},
  title = {Dueling Network Architectures for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
  series = {PMLR},
  volume = {48},
  pages = {1995--2003},
  year = {2016}
}
